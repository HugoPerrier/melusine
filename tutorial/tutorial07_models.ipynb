{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models subpackage tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel class is a generic class used to manage neural networks implemented with Keras. It offers methods to save, load, train and use for classification the neural networks.\n",
    "\n",
    "Melusine provides two built-in Keras model : cnn_model and rnn_model based on the models used in-house at Maif. However the user is free to implement neural networks tailored for its needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel class can take as input either :\n",
    "- a text input : a cleaned text, usually the cleaned body or the concatenation of the cleaned body and the cleaned header.\n",
    "- a text input and a metadata input : the metadata input has to be dummified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.data.data_loader import load_email_data\n",
    "df_emails = load_email_data(type=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new clean_text column is the concatenation of the clean_header column and the clean_body column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emails['clean_text'] = df_emails['clean_header'] + \" \" + df_emails['clean_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'devis habitation je suis client chez vous pouvez vous m etablir un devis pour mon fils qui souhaite louer lappartement suivant : 25 rue du rueimaginaire  flag_cp_ '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emails.clean_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the metadata used are :\n",
    "- the extension : gmail, outlook, wanadoo..\n",
    "- the day of the week at which the email has been sent\n",
    "- the hour at which the email has been sent\n",
    "- the minute at which the email has been sent\n",
    "- the attachment types : pdf, png .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is a Pandas dataframe with a clean_text column that will be used for the text input and columns containing the dummified metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_emails.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y is a numpy array containing the encoded labels :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = df_emails['label']\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 10,  3,  0,  0,  4,  7, 10,  1, 10,  2,  5, 10, 10,  4,  7,  7,\n",
       "       10,  0,  9,  4, 10,  4,  7, 10, 10,  6,  7,  3,  8, 10, 10, 10,  4,\n",
       "        7,  3,  5,  4,  4, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NeuralModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.models.train import NeuralModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel class is a generic class used to manage neural networks implemented with Keras. It offers methods to save, load, train and use for classification the neural networks.\n",
    "\n",
    "Its arguments are :\n",
    "- **architecture_function :** a function returning a Model instance from Keras.\n",
    "- **pretrained_embedding :** the pretrained embedding matrix as an numpy array.\n",
    "- **text_input_column :** the name of the column that will provide the text input, by default clean_text.\n",
    "- **meta_input_list :** the list of the names of the columns containing the metadata. If empty list or None the model is used without metadata. Default value, ['extension', 'dayofweek', 'hour', 'min'].\n",
    "- **vocab_size :** the size of vocabulary for neurol network model. Default value, 25000.\n",
    "- **seq_size :** the maximum size of input for neural model. Default value, 100.\n",
    "- **loss :** the loss function for training. Default value, 'categorical_crossentropy'.\n",
    "- **batch_size :** the size of batches for the training of the neural network model. Default value, 4096.\n",
    "- **n_epochs :** the number of epochs for the training of the neural network model. Default value, 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### architecture_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.models.neural_architectures import cnn_model, rnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**architecture_function** is a function returning a Model instance from Keras.\n",
    "Melusine provides two built-in neural networks : **cnn_model** and **rnn_model** based on the models used in-house at Maif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pretrained_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding have to be trained on the user's dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melusine.nlp_tools.embedding import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embedding = Embedding(tokens_column=\"tokens\", workers=1, min_count=5)\n",
    "pretrained_embedding.train(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralModel used with text and metadata input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This neural network model will use the **clean_text** column for the text input and the dummified **extension**, **dayofweek**, **hour** and **min** as metadata input :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = NeuralModel(architecture_function=cnn_model,\n",
    "                       pretrained_embedding=pretrained_embedding,\n",
    "                       text_input_column=\"clean_text\",\n",
    "                       meta_input_list=['extension','attachment_type', 'dayofweek', 'hour', 'min'],\n",
    "                       n_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training, logs are saved in \"train\" situated in the data directory. Use tensorboard to follow training using \n",
    "- \"tensorboard --logdir data\" from your terminal  \n",
    "- directly from a notebook with \"%load_ext tensorboard\" and \"%tensorboard --logdir data\" magics command (see https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4256 - accuracy: 0.0750\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:From /home/78169t/.conda/envs/sentiment/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3756 - accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3082 - accuracy: 0.2000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2003 - accuracy: 0.2250\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1307 - accuracy: 0.2750\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9719 - accuracy: 0.3250\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0063 - accuracy: 0.2500\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8990 - accuracy: 0.4000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9821 - accuracy: 0.2750\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9568 - accuracy: 0.2750\n"
     ]
    }
   ],
   "source": [
    "nn_model.fit(X,y,tensorboard_log_dir=\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../docs/_static/tensorboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **save_nn_model** method saves :\n",
    "- the Keras model as a json file \n",
    "- the weights as a h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.save_nn_model(\"./data/nn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the **save_nn_model** used the NeuralModel object can be saved as a pickle file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "_ = joblib.dump(nn_model,\"./data/nn_model.pickle\",compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NeuralModel saved as a pickle file has to be loaded first : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = joblib.load(\"./data/nn_model.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the Keras model and its weights can be loaded :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.load_nn_model(\"./data/nn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = nn_model.predict(X)\n",
    "y_res = le.inverse_transform(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'habitation', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralModel used with only text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_input_list=None\n",
    "\n",
    "nn_model = NeuralModel(architecture_function=cnn_model,\n",
    "                       pretrained_embedding=pretrained_embedding,\n",
    "                       text_input_column=\"clean_text\",\n",
    "                       meta_input_list=meta_input_list,\n",
    "                       n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule',\n",
       "       'vehicule', 'vehicule', 'vehicule', 'vehicule', 'vehicule'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res = nn_model.predict(X)\n",
    "y_res = le.inverse_transform(y_res)\n",
    "y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpe_melusine",
   "language": "python",
   "name": "hpe_melusine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
